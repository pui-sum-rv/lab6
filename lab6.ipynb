{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipXpivMK_PT8"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ferit-osirv/lab6/blob/main/lab6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8vtuqXEBP1j"
      },
      "source": [
        "# Lab 6 -  Feature and Object Detection\n",
        "\n",
        "These laboratory excersises are solved on Google Colab and are save on GitHub repo that is connected to GitHub Classroom.\n",
        "\n",
        "## Tools You need to use to Submit Assignments\n",
        "\n",
        "In this document, you will solve tasks. This is a Jupyter Notebook which has the **.ipynb** extension, is an interactive web environment for data analysis, visualization, solution presentations, education, and more.\n",
        "\n",
        "**Google Colab** is a tool that allows you to run and share Jupyter Notebook files on Google's servers, including the use of Google's CPU, GPU, and TPU resources. Colab is like Google Docs for Jupyter Notebooks. **Google Colab does not automatically save your assignment to GitHub.**\n",
        "\n",
        "**You use GitHub to save and submit your assignments.** When you accept the assignment through GitHub Classroom, a repository is automatically created on your GitHub account with a copy of the task. This is where you will save your solutions. Saving your solutions submits the tasks for that lab.\n",
        "\n",
        "## How to Solve the Tasks?\n",
        "1. Accept the task via the Google Classroom link that you will receive. Google Classroom will create a repository on your account.\n",
        "2. Go to the newly created repository on your account and click on the .ipynb file, then click Open in Colab.\n",
        "3. You will solve the tasks in Google Colab.\n",
        "\n",
        "## How to Save (Submit) Tasks?\n",
        "\n",
        "1. In Google Colab, click on the Open settings gear icon in the top-right corner.\n",
        "2. Click on the GitHub tab and check the box for Access private repositories and organizations.\n",
        "3. A new window will open for you to grant access to GitHub. For ferit-osirv, click Grant.\n",
        "4. Save and exit the settings.\n",
        "5. Click on File > Save a copy in GitHub.\n",
        "6. Select the lab repository that includes your name.\n",
        "\n",
        "> *Note:* You only need to complete steps 1-4 the first time.\n",
        "\n",
        "7. Click on **File > Save a copy in GitHub**.\n",
        "8. Select created repository **koji uključuje vaše ime**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feUPz7IDCbDx"
      },
      "source": [
        "## Copying Files from the GitHub Repository\n",
        "\n",
        "For completing the exercises, you will need images and other files that will be stored in the GitHub repository of the exercise. A command like this will be available in the notebook for each exercise. It will copy the files from GitHub to the Google Colab environment.\n",
        "\n",
        "**You need to run this command before starting each exercise.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpP_i0KgCefb",
        "outputId": "ab38ff89-73f1-4a85-fcfb-25a23d5c4d91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'clone'...\n",
            "remote: Enumerating objects: 25, done.\u001b[K\n",
            "remote: Counting objects: 100% (25/25), done.\u001b[K\n",
            "remote: Compressing objects: 100% (25/25), done.\u001b[K\n",
            "remote: Total 25 (delta 3), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (25/25), done.\n"
          ]
        }
      ],
      "source": [
        "!rm -rf clone && git clone https://github.com/ferit-osirv/lab6 clone && cp -a clone/. .\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIPg8Vf9Cr8D"
      },
      "source": [
        "**Google Colab will occasionally delete all files**. Therefore, you might need to rerun this command between sessions. If you encounter errors indicating that files do not exist, try running the command again."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nk-M0j7ToRmf"
      },
      "source": [
        "# Object detection algorithms (P1)\n",
        "\n",
        "Broadly speaking, object detection can be broken down into 'traditional' image processing methods, and deep learning-based approaches.\n",
        "\n",
        "In more traditional based approaches, computer vision techniques are used to look at various features of an image, such as the color histogram or edges, to identify groups of pixels that may belong to an object. \n",
        "\n",
        "On the other hand, deep learning-based approaches employ convolutional neural networks (CNNs) to perform end-to-end, unsupervised object detection, in which features don’t need to be defined and extracted separately. \n",
        "\n",
        "For now, in this lab we will focus on traditional image detection methods, while deep learning methods which have become the state-of-the-art approaches for object detection, will be covered in further laboratory excersises. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZMH3pFrQ_vf"
      },
      "source": [
        "## Template Matching Algorithm\n",
        "\n",
        "Template Matching is a method for searching and finding the location of a template image in a larger image. \n",
        "\n",
        "In OpenCV, template matching is implemented inside ```cv2.matchTemplate``` function. \n",
        "\n",
        "So what exactly is the ```cv2.matchTemplate``` function doing? Essentially, this function takes a “sliding window” of our query image and slides it across our puzzle image from left to right and top to bottom, one pixel at a time. Then, for each of these locations, we compute the correlation coefficient to determine how “good” or “bad” the match is.\n",
        "\n",
        "Regions with sufficiently high correlation can be considered “matches” for our image template. There are a variety of methods to perform template matching, \n",
        "based on different correlation coefficients. \n",
        "\n",
        "Definitions of different correlation coefficients can be found at: \n",
        "https://docs.opencv.org/2.4/modules/imgproc/doc/object_detection.html\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fiXZwj7Clagx"
      },
      "source": [
        "### Assigment 2 - Object detection using template matching"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "VFae9b_wSh1S"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['figure.figsize'] = [10, 8] # enlarge inline plots\n",
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jnwQmLS0dLnK"
      },
      "outputs": [],
      "source": [
        "# Load full input image \n",
        "full = cv2.imread('images/cat.jpg')\n",
        "full = cv2.cvtColor(full, cv2.COLOR_BGR2RGB)\n",
        "plt.imshow(full)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RztesRCkjbYv"
      },
      "outputs": [],
      "source": [
        "# Load Template image\n",
        "# This is a subset of the previous image, note how its actually the exact image\n",
        "template = cv2.imread('images/cat_face.jpg')\n",
        "template = cv2.cvtColor(template, cv2.COLOR_BGR2RGB)\n",
        "plt.imshow(template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "TIyNa72KTrzS"
      },
      "outputs": [],
      "source": [
        "height, width,channels = template.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "bC3k2d_qjc0q"
      },
      "outputs": [],
      "source": [
        "# Define 6 different template matching methods\n",
        "# TODO:\n",
        "methods = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LerYqIjxjeRJ"
      },
      "outputs": [],
      "source": [
        "for m in methods:\n",
        "    \n",
        "    # Create a copy of the image\n",
        "    full_copy = full.copy()\n",
        "    \n",
        "    # Get the actual function instead of the string\n",
        "    method = eval(m)\n",
        "\n",
        "    # apply template matching algorithm\n",
        "    res = cv2.matchTemplate(full_copy,template,method)\n",
        "    \n",
        "    # grab the Max and Min values, plus their locations\n",
        "    #TODO:\n",
        "    min_val, max_val, min_loc, max_loc = \n",
        "        \n",
        "    # if the method is TM_SQDIFF or TM_SQDIFF_NORMED, take minimum\n",
        "    \n",
        "    if method in [cv2.TM_SQDIFF, cv2.TM_SQDIFF_NORMED]:\n",
        "    #TODO: \n",
        "    else:\n",
        "    #TODO: \n",
        "        \n",
        "    # assign the bottom right of the rectangle\n",
        "    bottom_right = (top_left[0] + width, top_left[1] + height)\n",
        "    # draw the red rectangle\n",
        "    cv2.rectangle(full_copy,top_left, bottom_right, 255, 10)\n",
        "\n",
        "    # Plot the Images\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.imshow(res)\n",
        "    plt.title('Result of Template Matching')\n",
        "    \n",
        "    plt.subplot(1,2,2)\n",
        "    plt.imshow(full_copy)\n",
        "    plt.title('Detected Point')\n",
        "    plt.suptitle(m)  \n",
        "    plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "lab6.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
