{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipXpivMK_PT8"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ferit-osirv/lab6/blob/main/lab6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8vtuqXEBP1j"
      },
      "source": [
        "# Lab 6 -  Feature and Object Detection\n",
        "\n",
        "Ove laboratorijske vježbe se rješavaju u Google Colabu i spremaju na GitHub repozitorij koji je povezan na GitHub Classroom.\n",
        "\n",
        "## Kako riješiti zadatke?\n",
        "\n",
        "1. Prihvatite zadatak putem Google Classroom linka koji ćete dobiti. Google Classroom će kreirati repozitorij na vašem računu.\n",
        "2. Uđite u novokreiran repozitorij na vašem računu i kliknite na **.ipynb** datoteku, zatim kliknite **Open in Colab**.\n",
        "3. Zadatke rješavate u Google Colabu.\n",
        "\n",
        "## Kako spremiti (predati) zadatke?\n",
        "\n",
        "1. Unutar **Google Colaba** kliknite na **Open settings** kotačić u gornjem desnom kutu.\n",
        "2. Kliknite na **GitHub** tab i odaberite kvačicu za **Access private repositories and organizations**.\n",
        "3. Otvorit će se novi prozor da dodate pristup GitHubu. Kod **ferit-osirv** kliknite **Grant**.  \n",
        "4. Spremite i izađite iz postavki.\n",
        "\n",
        "\n",
        "5. Kliknite na **File > Save a copy in GitHub**.\n",
        "6. Odaberite kreiran repozitorij labosa **koji uključuje vaše ime**.\n",
        "\n",
        "> *Napomena:* Korake 1-4 morate napraviti samo prvi put."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feUPz7IDCbDx"
      },
      "source": [
        "## Kopiranje datoteka iz GitHub repozitorija\n",
        "\n",
        "Za izradu vježbi bit će vam potrebne slike i druge datoteke koje će se nalaziti u GitHub repozitoriju vježbe. Ovakva komanda će biti dostupna u notebooku svake vježbe. Ona će kopirati datoteke s GitHuba u Google Colab okruženje.\n",
        "\n",
        "**Ovu komandu je potrebno pokrenuti prije nego što krenete raditi svaku vježbu.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpP_i0KgCefb",
        "outputId": "ab38ff89-73f1-4a85-fcfb-25a23d5c4d91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'clone'...\n",
            "remote: Enumerating objects: 25, done.\u001b[K\n",
            "remote: Counting objects: 100% (25/25), done.\u001b[K\n",
            "remote: Compressing objects: 100% (25/25), done.\u001b[K\n",
            "remote: Total 25 (delta 3), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (25/25), done.\n"
          ]
        }
      ],
      "source": [
        "!rm -rf clone && git clone https://github.com/ferit-osirv/lab6 clone && cp -a clone/. .\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIPg8Vf9Cr8D"
      },
      "source": [
        "**Google Colab će povremeno obrisati sve datoteke.** Tako da će možda biti potrebno ponovno pokrenuti ovu komandu između dvije sesije. Ako dobivate greške da datoteke ne postoje, probajte ponovno pokrenuti gornju komandu."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nk-M0j7ToRmf"
      },
      "source": [
        "# Object detection algorithms (P1)\n",
        "\n",
        "Broadly speaking, object detection can be broken down into 'traditional' image processing methods, and deep learning-based approaches.\n",
        "\n",
        "In more traditional based approaches, computer vision techniques are used to look at various features of an image, such as the color histogram or edges, to identify groups of pixels that may belong to an object. \n",
        "\n",
        "On the other hand, deep learning-based approaches employ convolutional neural networks (CNNs) to perform end-to-end, unsupervised object detection, in which features don’t need to be defined and extracted separately. \n",
        "\n",
        "For now, in this lab we will focus on traditional image detection methods, while deep learning methods which have become the state-of-the-art approaches for object detection, will be covered in further laboratory excersises. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZMH3pFrQ_vf"
      },
      "source": [
        "## Template Matching Algorithm\n",
        "\n",
        "Template Matching is a method for searching and finding the location of a template image in a larger image. \n",
        "\n",
        "In OpenCV, template matching is implemented inside ```cv2.matchTemplate``` function. \n",
        "\n",
        "So what exactly is the ```cv2.matchTemplate``` function doing? Essentially, this function takes a “sliding window” of our query image and slides it across our puzzle image from left to right and top to bottom, one pixel at a time. Then, for each of these locations, we compute the correlation coefficient to determine how “good” or “bad” the match is.\n",
        "\n",
        "Regions with sufficiently high correlation can be considered “matches” for our image template. There are a variety of methods to perform template matching, \n",
        "based on different correlation coefficients. \n",
        "\n",
        "Definitions of different correlation coefficients can be found at: \n",
        "https://docs.opencv.org/2.4/modules/imgproc/doc/object_detection.html\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fiXZwj7Clagx"
      },
      "source": [
        "### Assigment 2 - Object detection using template matching"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "VFae9b_wSh1S"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['figure.figsize'] = [10, 8] # enlarge inline plots\n",
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jnwQmLS0dLnK"
      },
      "outputs": [],
      "source": [
        "# Load full input image \n",
        "full = cv2.imread('images/cat.jpg')\n",
        "full = cv2.cvtColor(full, cv2.COLOR_BGR2RGB)\n",
        "plt.imshow(full)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RztesRCkjbYv"
      },
      "outputs": [],
      "source": [
        "# Load Template image\n",
        "# This is a subset of the previous image, note how its actually the exact image\n",
        "template = cv2.imread('images/cat_face.jpg')\n",
        "template = cv2.cvtColor(template, cv2.COLOR_BGR2RGB)\n",
        "plt.imshow(template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "TIyNa72KTrzS"
      },
      "outputs": [],
      "source": [
        "height, width,channels = template.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "bC3k2d_qjc0q"
      },
      "outputs": [],
      "source": [
        "# Define 6 different template matching methods\n",
        "# TODO:\n",
        "methods = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LerYqIjxjeRJ"
      },
      "outputs": [],
      "source": [
        "for m in methods:\n",
        "    \n",
        "    # Create a copy of the image\n",
        "    full_copy = full.copy()\n",
        "    \n",
        "    # Get the actual function instead of the string\n",
        "    method = eval(m)\n",
        "\n",
        "    # apply template matching algorithm\n",
        "    res = cv2.matchTemplate(full_copy,template,method)\n",
        "    \n",
        "    # grab the Max and Min values, plus their locations\n",
        "    #TODO:\n",
        "    min_val, max_val, min_loc, max_loc = \n",
        "        \n",
        "    # if the method is TM_SQDIFF or TM_SQDIFF_NORMED, take minimum\n",
        "    \n",
        "    if method in [cv2.TM_SQDIFF, cv2.TM_SQDIFF_NORMED]:\n",
        "    #TODO: \n",
        "    else:\n",
        "    #TODO: \n",
        "        \n",
        "    # assign the bottom right of the rectangle\n",
        "    bottom_right = (top_left[0] + width, top_left[1] + height)\n",
        "    # draw the red rectangle\n",
        "    cv2.rectangle(full_copy,top_left, bottom_right, 255, 10)\n",
        "\n",
        "    # Plot the Images\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.imshow(res)\n",
        "    plt.title('Result of Template Matching')\n",
        "    \n",
        "    plt.subplot(1,2,2)\n",
        "    plt.imshow(full_copy)\n",
        "    plt.title('Detected Point')\n",
        "    plt.suptitle(m)  \n",
        "    plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "lab6.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
